---
title: Agentic Rag Portfolio
emoji: ğŸ“‰
colorFrom: green
colorTo: blue
sdk: gradio
sdk_version: 6.2.0
app_file: app.py
pinned: false
license: mit
---

<p align="center">
  <a href="README.md">English</a> | 
  <a href="README_zh.md">ä¸­æ–‡</a>
</p>

# Agentic RAG System

[ä¸­æ–‡ç‰ˆ README](README_zh.md)

## ğŸ¯ Project Overview

This project is built to explore and implement:
- **Vector Embeddings**: Dense + Sparse hybrid retrieval using Qdrant
- **Agent Orchestration**: LangGraph-based workflow for query processing
- **RAG Pipeline**: Document ingestion, chunking, indexing, and retrieval

## âœï¸ What I Built

- Built an Agentic RAG system from scratch with LangGraph, adapted for Chinese long documents
- Implemented LangGraph state management and graph orchestration: main graph for dialogue + aggregation, subgraph for deep retrieval
- Added hierarchical indexing (Parent-Child) to balance precision and context
- Integrated hybrid retrieval (Dense + Sparse) to improve recall
- Designed conversation memory for multi-turn dialogue; added query rewriting and human-in-the-loop controls
- Implemented multi-agent Map-Reduce to handle complex queries

## ğŸš€ Key Features

- **Hybrid Retrieval**: Combines dense embeddings (BGE-zh) and sparse embeddings (BM25) for better search accuracy
- **LangGraph Workflow**: Implements conversation memory, query rewriting, and document retrieval as graph nodes
- **Chinese Optimization**: Customized for Chinese documents with BGE-zh embedding model
- **Hierarchical Chunking**: Parent-child chunking strategy for precision + context
- **Gradio UI**: Interactive interface for document management and Q&A

## ğŸ› ï¸ Tech Stack

- **Framework**: LangGraph, LangChain
- **Vector DB**: Qdrant (local file-based)
- **Embeddings**: 
  - Dense: BAAI/bge-base-zh-v1.5
  - Sparse: Qdrant/bm25
- **LLM**: Qwen-max via DashScope API
- **UI**: Gradio

## ğŸ“š What I Learned

1. **LangGraph Concepts**: 
   - State management with Pydantic models
   - Node functions and conditional edges
   - Graph compilation and checkpointing

2. **RAG Architecture**: 
   - Parent-child chunking strategy
   - Hybrid retrieval (dense + sparse)
   - Query rewriting and clarification

3. **Vector Databases**: 
   - Qdrant setup and collection management
   - Similarity search with score thresholds
   - Sparse vector support

4. **Agent Workflows**: 
   - Query analysis and rewriting
   - Tool calling (search, retrieve)
   - Response aggregation

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ core/                    # Core RAG components
â”‚   â”œâ”€â”€ rag_system.py       # Main RAG system initialization
â”‚   â”œâ”€â”€ chat_interface.py   # Chat interface handler
â”‚   â””â”€â”€ document_manager.py # Document ingestion and management
â”œâ”€â”€ db/                      # Database management
â”‚   â”œâ”€â”€ vector_db_manager.py    # Qdrant vector DB operations
â”‚   â””â”€â”€ parent_store_manager.py # Parent chunk storage (JSON)
â”œâ”€â”€ rag_agent/              # LangGraph agent implementation
â”‚   â”œâ”€â”€ graph.py            # Graph construction and compilation
â”‚   â”œâ”€â”€ nodes.py            # Node functions (summarize, rewrite, agent)
â”‚   â”œâ”€â”€ edges.py            # Conditional routing logic
â”‚   â”œâ”€â”€ graph_state.py      # State definitions
â”‚   â”œâ”€â”€ prompts.py          # System prompts for LLM
â”‚   â”œâ”€â”€ tools.py            # Retrieval tools (search, retrieve)
â”‚   â””â”€â”€ schemas.py          # Pydantic data models
â”œâ”€â”€ ui/                      # User interface
â”‚   â”œâ”€â”€ gradio_app.py       # Gradio UI components
â”‚   â””â”€â”€ css.py              # Custom styling
â”œâ”€â”€ config.py                # Configuration (models, chunk sizes)
â”œâ”€â”€ document_chunker.py      # Document chunking strategy
â”œâ”€â”€ util.py                  # PDF to Markdown conversion
â””â”€â”€ app.py                   # Application entry point
```

## ğŸš¦ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure API Keys

Create `config_secrets.json` in the project root:

```json
{
  "DASHSCOPE_API_KEY": "your-dashscope-api-key"
}
```

Or set environment variable:
```bash
export DASHSCOPE_API_KEY="your-api-key"
```

### 3. Run the Application

```bash
python app.py
```

The Gradio interface will launch at `http://127.0.0.1:7860`

## ğŸ“– How It Works

1. **Document Ingestion**: 
   - Upload PDF/Markdown files through the UI
   - Convert to Markdown format
   - Split into parent and child chunks

2. **Indexing**:
   - Child chunks: Small, precise chunks (500 tokens) for initial retrieval
   - Parent chunks: Larger context chunks (2000-10000 tokens) stored separately
   - Both embedded and stored in Qdrant

3. **Query Processing**:
   - Conversation summarization for context
   - Query analysis and rewriting
   - Hybrid retrieval (dense + sparse)
   - Parent chunk retrieval for full context
   - Response generation with source citations

## ğŸ”§ Customization

The system is designed to be modular:

- **LLM Provider**: Switch between DashScope, OpenAI, Ollama in `config.py`
- **Embedding Models**: Change dense/sparse models in `config.py`
- **Chunking Strategy**: Adjust sizes in `config.py`
- **Agent Workflow**: Modify nodes and edges in `rag_agent/`

## ğŸ“ Notes
- Focused on RAG + Agent architecture practice; provides a runnable demo (Gradio UI + Qdrant local storage)
- Uses cloud APIs by default; local models (e.g., Ollama) are optional
- Customized for Chinese document processing

## ğŸ”— References

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [LangChain Documentation](https://python.langchain.com/)

## ğŸ“„ License
MIT License.
